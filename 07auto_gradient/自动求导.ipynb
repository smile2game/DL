{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.arange(4.0)\n",
    "x.requires_grad_(True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x,x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(retain_graph=True)\n",
    "#注意这里的梯度，不是x对x的梯度，而是y进行反向传播后，赋值给x的梯度\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果没有下面这一行，就会不断自动累加梯度\n",
    "x.grad.zero_()\n",
    "\n",
    "y=x.sum()\n",
    "y.backward()\n",
    "x.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n等价于y.sum().backward()\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x* x\n",
    "y.backward(torch.ones(len(x)))   #对于非标量进行backward，需要传入参数‘gradient’指定\n",
    "#我们计算的目的不是微分矩阵，而是一个样本的偏导数之和\n",
    "x.grad\n",
    "'''\n",
    "等价于y.sum().backward()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 4., 9.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x*x\n",
    "# #这里我们利用detach，将u视作常数，而不与x发生关联\n",
    "u = y.detach()\n",
    "#这里应该可以固定参数的呀\n",
    "z= u*x\n",
    "z.sum().backward()\n",
    "x.grad\n",
    "#给我整不会了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于复杂控制流的求导："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(102400.),\n",
       " tensor(-162351.7188, grad_fn=<MulBackward0>),\n",
       " tensor(-1.5855, requires_grad=True),\n",
       " tensor(True))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a):\n",
    "    b= a*2\n",
    "    while b.norm() < 1000:\n",
    "        b=  b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else: \n",
    "        c = 100 * b \n",
    "    return c \n",
    "#一个记录梯度的标量a\n",
    "a =  torch.randn(size = (),requires_grad = True)\n",
    "d = f(a)\n",
    "d.backward()\n",
    "a.grad,d,a,a.grad==d/a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明:\n",
    "\n",
    "1.pytorch自动累计梯度：批量情况\n",
    "\n",
    "2.为什么求导不喜欢对向量：因为标量loss简单，好球\n",
    "\n",
    "3.如果么有进行backward，当然就不会对grad进行梯度赋值啦，这是很贵的一件事。\n",
    "\n",
    "4.计算的时候都是有向图，树状图，不喜欢环状图\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
