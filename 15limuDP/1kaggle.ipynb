{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一。数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(name,cache_dir = os.path.join('..','data')):\n",
    "    assert name in DATA_HUB,f\"{name} 不存在于 {DATA_HUB}.\"\n",
    "    url,sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir,exist_ok= True)\n",
    "    fname = os.path.join(cache_dir,url.split('/')[-1])\n",
    "    if os.path.exists(fname):                     #实际上这是已存在防止重复下载的代码\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname,'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname\n",
    "    print(f'正在从{url}下载{fname}')\n",
    "    r = requests.get(url,stream =True,verify = True)\n",
    "    with open(fname,'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract(name,folder = None):#这是解压函数\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)#找到前一级\n",
    "    data_dir,ext  = os.path.splitext(fname)   #分割后缀\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname,'r')\n",
    "    elif ext in ('.tar','.gz'):\n",
    "        fp  = tarfile.open(fname,'r')\n",
    "    else:\n",
    "        assert False,'只有zip/tar可以被解压哦'\n",
    "    fp.extractcall(base_dir) #提取出来\n",
    "    return os.path.join(base_dir,folder) if folder else data_dir\n",
    "\n",
    "def download_all():#这是下载函数\n",
    "    for name in DATA_HUB:\n",
    "        download(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB['kaggle_house_train'] = (  #@save\n",
    "    DATA_URL + 'kaggle_house_pred_train.csv',\n",
    "    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
    "\n",
    "DATA_HUB['kaggle_house_test'] = (  #@save\n",
    "    DATA_URL + 'kaggle_house_pred_test.csv',\n",
    "    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载..\\data\\kaggle_house_pred_train.csv\n",
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载..\\data\\kaggle_house_pred_test.csv\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n",
      "0         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
      "1         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n",
      "2         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n",
      "\n",
      "  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0         NaN       0       2    2008        WD         Normal  \n",
      "1         NaN       0       5    2007        WD         Normal  \n",
      "2         NaN       0       9    2008        WD         Normal  \n",
      "\n",
      "[3 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))#合并成all_features\n",
    "print(all_features[0:3,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二。数据预处理"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
