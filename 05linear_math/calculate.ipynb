{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "x= torch.tensor([3.0])\n",
    "y =torch.tensor([2.0])\n",
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元素按照指定axis求和:消除这个维度，全部求和，axis=0是最大求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.5000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(20*2,dtype = torch.float32).reshape(2,5,4)\n",
    "a.sum()\n",
    "a_axis0=a.sum(axis=0)\n",
    "a_axis2 = a.sum(axis=2)\n",
    "#这里可以一步一步来\n",
    "a_axis01 = a.sum(axis = [0,1]) \n",
    " \n",
    "#计算均值\n",
    "mean = a.mean()\n",
    "a.sum()/a.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不想丢掉这个维度:这里其实是维度型归一化   触发广播机制，维度层数一致，对应维度进行复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0455, 0.0833, 0.1154],\n",
       "         [0.1429, 0.1667, 0.1875, 0.2059],\n",
       "         [0.2222, 0.2368, 0.2500, 0.2619],\n",
       "         [0.2727, 0.2826, 0.2917, 0.3000],\n",
       "         [0.3077, 0.3148, 0.3214, 0.3276]],\n",
       "\n",
       "        [[1.0000, 0.9545, 0.9167, 0.8846],\n",
       "         [0.8571, 0.8333, 0.8125, 0.7941],\n",
       "         [0.7778, 0.7632, 0.7500, 0.7381],\n",
       "         [0.7273, 0.7174, 0.7083, 0.7000],\n",
       "         [0.6923, 0.6852, 0.6786, 0.6724]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_a = a.sum(axis = 0,keepdims =True)\n",
    "a/sum_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]],\n",
       "\n",
       "        [[20., 22., 24., 26.],\n",
       "         [28., 30., 32., 34.],\n",
       "         [36., 38., 40., 42.],\n",
       "         [44., 46., 48., 50.],\n",
       "         [52., 54., 56., 58.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算累加和\n",
    "a.cumsum(axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向量乘法有两种：点积(对应元素相乘求和)和×积（矩阵相乘） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 42.,  48.,  54.],\n",
       "        [114., 136., 158.],\n",
       "        [186., 224., 262.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵的点乘\n",
    "a1 = torch.arange(4,dtype = torch.float32)\n",
    "a2 = torch.ones(4,dtype =  torch.float32)\n",
    "a1,a2,torch.dot(a1,a2)\n",
    "#矩阵*向量\n",
    "a3 = torch.ones(4,dtype = torch.float32)\n",
    "a4 = torch.arange(12,dtype = torch.float32).reshape((3,4))\n",
    "a3.shape,a4.shape\n",
    "torch.mv(a4,a3)\n",
    "#向量乘：\n",
    "a5 = torch.arange(12,dtype = torch.float32).reshape((4,3))\n",
    "torch.mm(a4,a5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵的范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.4944)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#L2范数\n",
    "u = torch.tensor ([3.0,-4.0])\n",
    "torch.norm(u)\n",
    "#L1范数\n",
    "torch.abs(u).sum()\n",
    "#矩阵范数：F范数\n",
    "torch.norm(a4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0747f93ff6db21b2db2bf35ad4858dd0825b9c21797c41b4cc32097944ab3f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
